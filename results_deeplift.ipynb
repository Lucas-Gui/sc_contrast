{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "from pprint import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport models\n",
    "%aimport main\n",
    "%aimport data_utils\n",
    "%aimport contrastive_data\n",
    "%aimport scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contrastive_data import *\n",
    "from data_utils import *\n",
    "from main import *\n",
    "from models import *\n",
    "from scoring import *\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(To change for villarica : use wrangled Nabid data and filter genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 70\n",
    "data_path = '~/data/nabid/pilot2filtered.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path)\n",
    "genes = pd.read_csv(f'out/{N}_best_genes.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    }
   ],
   "source": [
    "X = data[genes.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run from here to re-split without reloading all data\n",
    "\n",
    "(will be necessary if wtlike is changed however)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config-file = models/cls_tp53_0/cls_tp53_0_22/config.ini\n",
      "dest-name = cls_tp53_0\n",
      "verbose = 1\n",
      "loss = standard\n",
      "margin = 2.4360665047229384\n",
      "dropout = 0.3565534119325581\n",
      "weight-decay = 0.008166142039759013\n",
      "batch-size = 128\n",
      "positive-fraction = 0.472911131385171\n",
      "shape = [718, 718, 718, 718]\n",
      "embed-dim = 20\n",
      "lr = 3.325281264031996e-05\n",
      "scheduler = plateau\n",
      "patience = 134\n",
      "cosine-t = 207\n",
      "task = classifier\n",
      "alpha = 0\n",
      "n-epochs = 600\n",
      "knn = 5\n",
      "n-workers = 0\n",
      "bag-size = 0\n",
      "mil-mode = attention\n"
     ]
    }
   ],
   "source": [
    "#CELL TO CHANGE\n",
    "run_name = 'cls_tp53_0_best'\n",
    "run_dir = 'TP53_all_single/best'\n",
    "BAG_SIZE = 50\n",
    "dir_name = join('models',run_dir)\n",
    "dataset_class = BatchDataset\n",
    "! cat models/{run_dir}/config.ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47834, 15945, 19999 exemples in data\n",
      "75 variants in train\n",
      "24 variants in unseen\n"
     ]
    }
   ],
   "source": [
    "df_train, df_seen, df_unseen = load_split(join(dir_name, 'split'), counts, )\n",
    "df_dict = {\n",
    "    'train':df_train,\n",
    "    'seen':df_seen,\n",
    "    'unseen':df_unseen,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of top 11 variants in training set: 8\n"
     ]
    }
   ],
   "source": [
    "n_mut = len([v for v in df_train['variant'].unique() if v in MAIN_MUTANTS])\n",
    "print(f\"Number of top {len(MAIN_MUTANTS)} variants in training set: {n_mut}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obsolete - all runs should be grouped by control now\n",
    "# print(run_name)\n",
    "# group_original = True\n",
    "# if ('control' == df_train.variant).any():\n",
    "#     if  ('control' == df_unseen.variant).any():\n",
    "#         print('WT-like not merged together in original data')\n",
    "#         group_original = False\n",
    "#     else:\n",
    "#         print('WT-like merged together in original data, put in train/seen')\n",
    "# else:\n",
    "#     print('WT-like merged together in original data, put in unseen')\n",
    "\n",
    "# print(f\"{group_wt_like=}\")\n",
    "\n",
    "# if group_original ^ group_wt_like: # xor\n",
    "#     raise ValueError(f'The data used to trained the model was {\"not \" if not group_original else \"\"}grouped \\\n",
    "#                      and the data now is {\"not \" if not group_wt_like else \"\"}grouped') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train, dl_seen, dl_unseen = make_loaders(\n",
    "    df_train, df_seen,df_unseen, batch_size=64, dataset_class=dataset_class,n_workers=1,pos_frac=0.5, \n",
    "    dataset_kwargs={'bag_size':BAG_SIZE})\n",
    "dl_dict = {\n",
    "    'train':dl_train,\n",
    "    'seen':dl_seen,\n",
    "    'unseen':dl_unseen,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (network): MLP(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=1224, out_features=718, bias=True)\n",
       "      (1): ELU(alpha=1.0)\n",
       "      (2): Dropout(p=0.3565534119325581, inplace=False)\n",
       "      (3): Linear(in_features=718, out_features=718, bias=True)\n",
       "      (4): ELU(alpha=1.0)\n",
       "      (5): Dropout(p=0.3565534119325581, inplace=False)\n",
       "      (6): Linear(in_features=718, out_features=718, bias=True)\n",
       "      (7): ELU(alpha=1.0)\n",
       "      (8): Dropout(p=0.3565534119325581, inplace=False)\n",
       "      (9): Linear(in_features=718, out_features=718, bias=True)\n",
       "      (10): ELU(alpha=1.0)\n",
       "      (11): Dropout(p=0.3565534119325581, inplace=False)\n",
       "      (12): Linear(in_features=718, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=20, out_features=75, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model = torch.load(join(dir_name,'model.pkl'), map_location='cpu')\n",
    "model :Model = torch.load(join(dir_name,'best_model.pkl'), map_location='cpu')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"5_nn_ref_seen\": 0.029413609281906554,\n",
      "  \"i\": 233\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat models/{run_dir}/best_score.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fclass = variant_data.loc[df_seen.variant.unique(), 'Variant functional class']\n",
    "fclass = fclass.where(fclass.index.map(lambda x :( x[0] != x[-1]) and (x!= 'WT')), 'Synonymous').sort_values(key=lambda s: s.map(VFC_KEY))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
